{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import math\n",
    "import nibabel as nib\n",
    "import os\n",
    "import struct\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "from utils import *\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "\n",
    "# data\n",
    "data_dir = './data/'\n",
    "cases = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "D, H, W = 224, 160, 224\n",
    "\n",
    "# misc\n",
    "device = 'cuda'\n",
    "\n",
    "# keypoints / graph\n",
    "d_fixed = 5\n",
    "scale_moving = 1.25\n",
    "d_moving = 3\n",
    "k = 10\n",
    "k1 = 256\n",
    "\n",
    "# displacement space\n",
    "l_max = 9\n",
    "l_width = l_max * 2 + 1\n",
    "q = 3\n",
    "disp = torch.stack(torch.meshgrid(torch.arange(- q * l_max, q * l_max + 1, q),\n",
    "                                  torch.arange(- q * l_max, q * l_max + 1, q),\n",
    "                                  torch.arange(- q * l_max, q * l_max + 1, q))).permute(1, 2, 3, 0).contiguous().view(1, -1, 3).float()\n",
    "disp = (disp.flip(-1) * 2 / (torch.tensor([W, H, D]) - 1)).to(device)\n",
    "\n",
    "# patch\n",
    "patch_radius = 2\n",
    "patch_step = 2\n",
    "patch = torch.stack(torch.meshgrid(torch.arange(0, 2 * patch_radius + 1, patch_step),\n",
    "                                   torch.arange(0, 2 * patch_radius + 1, patch_step),\n",
    "                                   torch.arange(0, 2 * patch_radius + 1, patch_step))).permute(1, 2, 3, 0).contiguous().view(1, -1, 3).float() - patch_radius\n",
    "patch = (patch.flip(-1) * 2 / (torch.tensor([W, H, D]) - 1)).to(device)\n",
    "\n",
    "# pca\n",
    "pca_components = 64\n",
    "\n",
    "#LBPS\n",
    "slbp_iter = 5\n",
    "slbp_cost_scale = 10\n",
    "slbp_alpha = -50\n",
    "\n",
    "#LBPD\n",
    "dlbp_iter = 5\n",
    "dlbp_cost_scale = 1\n",
    "dlbp_alpha = -15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "orig_shapes  = torch.load(os.path.join(data_dir, 'preprocessed/resize_s/orig_shapes.pth'))\n",
    "imgs_fixed   = torch.zeros(len(cases),  1, D, H, W).pin_memory()\n",
    "masks_fixed  = torch.zeros(len(cases),  1, D, H, W).pin_memory()\n",
    "imgs_moving  = torch.zeros(len(cases),  1, D, H, W).pin_memory()\n",
    "masks_moving = torch.zeros(len(cases),  1, D, H, W).pin_memory()\n",
    "\n",
    "for i, case in enumerate(cases):\n",
    "    print('loading case {} ...'.format(case), end=' ')\n",
    "    t0 = time.time()\n",
    "\n",
    "    path_img_fixed   = os.path.join(data_dir, 'preprocessed/resize_s/case{}_img_fixed.nii.gz'.format(case + 1))\n",
    "    path_mask_fixed  = os.path.join(data_dir, 'preprocessed/resize_s/case{}_mask_fixed.nii.gz'.format(case + 1))\n",
    "    path_img_moving  = os.path.join(data_dir, 'preprocessed/resize_s/case{}_img_moving.nii.gz'.format(case + 1))\n",
    "    path_mask_moving = os.path.join(data_dir, 'preprocessed/resize_s/case{}_mask_moving.nii.gz'.format(case + 1))\n",
    "\n",
    "    img_fixed   = (torch.from_numpy(nib.load(path_img_fixed).get_data()).unsqueeze(0).unsqueeze(0).float().clamp_(-1000, 1500) + 1000) / 2500\n",
    "    mask_fixed  = torch.from_numpy(nib.load(path_mask_fixed).get_data()).unsqueeze(0).unsqueeze(0).bool()\n",
    "    img_moving  = (torch.from_numpy(nib.load(path_img_moving).get_data()).unsqueeze(0).unsqueeze(0).float().clamp_(-1000, 1500) + 1000) / 2500\n",
    "    mask_moving = torch.from_numpy(nib.load(path_mask_moving).get_data()).unsqueeze(0).unsqueeze(0).bool()\n",
    "\n",
    "    imgs_fixed[i]   = img_fixed\n",
    "    masks_fixed[i]  = mask_fixed\n",
    "    imgs_moving[i]  = img_moving\n",
    "    masks_moving[i] = mask_moving\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    print('{:.2f} s'.format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tre(case, disp_pred):\n",
    "    Do, Ho, Wo = orig_shapes[case].long().tolist()\n",
    "    path_lms_fixed   = os.path.join(data_dir, 'preprocessed/resize_s/case{}_lms_fixed.nii.gz'.format(case + 1))\n",
    "    lms_fixed   = kpts_pt(img_to_kpts(torch.from_numpy(nib.load(path_lms_fixed).get_fdata().astype(np.float32)).unsqueeze(0).unsqueeze(0).to(device), 300), (D, H, W))\n",
    "    lms_fixed_disp_pred = F.grid_sample(disp_pred.flip(1), lms_fixed.view(1, -1, 1, 1, 3), padding_mode='border', align_corners=True).view(3,-1).t()\n",
    "    lms_fixed_disp_pred = lms_fixed_disp_pred / 2 * (torch.tensor([Do, Ho, Wo]).to(device) - 1)\n",
    "    if case < 10:\n",
    "        return copdgene_error(os.path.join(data_dir, 'COPDgene'), case, lms_fixed_disp_pred.cpu())\n",
    "    elif case < 20:\n",
    "        return  dct4_error(os.path.join(data_dir, '4DCT'), case - 10, lms_fixed_disp_pred.cpu())\n",
    "    \n",
    "def discretize(kpts_fixed, kpts_fixed_feat, kpts_moving, kpts_moving_feat):\n",
    "    N_p_fixed = kpts_fixed.shape[1]\n",
    "    disp_range = disp.max(1, keepdim=True)[0]\n",
    "    dist = pdist2(kpts_fixed, kpts_moving)\n",
    "    ind = (-dist).topk(k1, dim=-1)[1]\n",
    "    candidates = - kpts_fixed.view(1, N_p_fixed, 1, 3) + kpts_moving[:, ind.view(-1), :].view(1, N_p_fixed, k1, 3)\n",
    "    candidates_cost = (kpts_fixed_feat.view(1, N_p_fixed, 1, -1) - kpts_moving_feat[:, ind.view(-1), :].view(1, N_p_fixed, k1, -1)).pow(2).mean(3, keepdim=True)\n",
    "    grid = inverse_grid_sample(candidates_cost.view(N_p_fixed, 1, -1), candidates[0]/disp_range, (l_width, l_width, l_width), mode='nearest', padding_mode='zeros', align_corners=True)\n",
    "    grid_norm = inverse_grid_sample(torch.ones_like(candidates_cost.view(N_p_fixed, 1, -1)), candidates[0]/disp_range, (l_width, l_width, l_width), mode='nearest', padding_mode='zeros', align_corners=True)\n",
    "    cost = grid  / (grid_norm + 0.000001)\n",
    "    cost[cost==0] = 1e4\n",
    "    return cost\n",
    "\n",
    "def lbp_graph(kpts_fixed):\n",
    "    A = knn_graph(kpts_fixed, k, include_self=False)[2][0]\n",
    "    edges = A.nonzero()\n",
    "    edges_idx = torch.zeros_like(A).long()\n",
    "    edges_idx[A.bool()] = torch.arange(edges.shape[0]).to(device)\n",
    "    edges_reverse_idx = edges_idx.t()[A.bool()]\n",
    "    return edges, edges_reverse_idx\n",
    "\n",
    "class EdgeConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EdgeConv, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*2, out_channels, 1, bias=False),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 1, bias=False),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 1, bias=False),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, ind):\n",
    "        B, N, D = x.shape\n",
    "        k = ind.shape[2]\n",
    "        \n",
    "        y = x.view(B*N, D)[ind.view(B*N, k)].view(B, N, k, D)\n",
    "        x = x.view(B, N, 1, D).expand(B, N, k, D)\n",
    "        \n",
    "        x = torch.cat([y - x, x], dim=3)\n",
    "        \n",
    "        x = self.conv(x.permute(0, 3, 1, 2))\n",
    "        x = F.max_pool2d(x, (1, k))\n",
    "        x = x.squeeze(3).permute(0, 2, 1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class GeometricFeatNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeometricFeatNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = EdgeConv(3, 32)\n",
    "        self.conv2 = EdgeConv(32, 32)\n",
    "        self.conv3 = EdgeConv(32, 64)\n",
    "        \n",
    "        self.conv4  = nn.Sequential(nn.Conv1d(64, 64, 1, bias=False),\n",
    "                                    nn.InstanceNorm1d(64),\n",
    "                                    nn.Conv1d(64, 64, 1))\n",
    "        \n",
    "    def forward(self, kpts_fixed, kpts_moving, k):\n",
    "        fixed_ind = knn_graph(kpts_fixed, k, include_self=True)[0]\n",
    "        x = self.conv1(kpts_fixed, fixed_ind)\n",
    "        x = self.conv2(x, fixed_ind)\n",
    "        x = self.conv3(x, fixed_ind)\n",
    "        \n",
    "        moving_ind = knn_graph(kpts_moving, k*3, include_self=True)[0]\n",
    "        y = self.conv1(kpts_moving, moving_ind)\n",
    "        y = self.conv2(y, moving_ind)\n",
    "        y = self.conv3(y, moving_ind)\n",
    "        \n",
    "        x = self.conv4(x.permute(0,2,1)).permute(0,2,1)\n",
    "        y = self.conv4(y.permute(0,2,1)).permute(0,2,1)\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sLBP(kpts_fixed, kpts_moving):\n",
    "    N_p_fixed = kpts_fixed.shape[1]\n",
    "\n",
    "    # inference\n",
    "    dist = pdist2(kpts_fixed, kpts_moving)\n",
    "    ind = (-dist).topk(k1, dim=-1)[1]\n",
    "    candidates = - kpts_fixed.view(1, N_p_fixed, 1, 3) + kpts_moving[:, ind.view(-1), :].view(1, N_p_fixed, k1, 3)\n",
    "    candidates_cost = torch.ones(1, N_p_fixed, k1, 1).to(device)\n",
    "    edges, edges_reverse_idx = lbp_graph(kpts_fixed)\n",
    "    messages = torch.zeros((edges.shape[0], k1)).to(device)\n",
    "    candidates_edges0 = candidates[0, edges[:, 0], :, :]\n",
    "    candidates_edges1 = candidates[0, edges[:, 1], :, :]\n",
    "    for _ in range(slbp_iter):\n",
    "        temp_message = torch.zeros((N_p_fixed, k1)).to(device).scatter_add_(0, edges[:, 1].view(-1, 1).expand(-1, k1), messages)\n",
    "        multi_data_cost = torch.gather(temp_message + candidates_cost.squeeze(), 0, edges[:,0].view(-1, 1).expand(-1, k1))\n",
    "        reverse_messages = torch.gather(messages, 0, edges_reverse_idx.view(-1, 1).expand(-1, k1))\n",
    "        multi_data_cost -= reverse_messages\n",
    "        messages = torch.zeros_like(multi_data_cost)\n",
    "        unroll_factor = 32\n",
    "        split = np.array_split(np.arange(multi_data_cost.shape[0]), unroll_factor)\n",
    "        for i in range(unroll_factor):\n",
    "            messages[split[i]] = torch.min(multi_data_cost[split[i]].unsqueeze(1) + slbp_cost_scale*(candidates_edges0[split[i]].unsqueeze(1) - candidates_edges1[split[i]].unsqueeze(2)).pow(2).sum(3), 2)[0]\n",
    "    reg_candidates_cost = (temp_message + candidates_cost.view(-1, k1)).unsqueeze(0)\n",
    "    kpts_fixed_disp_pred = (candidates * F.softmax(slbp_alpha * reg_candidates_cost.view(1, N_p_fixed, -1), 2).unsqueeze(3)).sum(2)\n",
    "\n",
    "    return kpts_fixed_disp_pred\n",
    "\n",
    "def sLBP_GF(kpts_fixed, kpts_moving, net):\n",
    "    N_p_fixed = kpts_fixed.shape[1]\n",
    "\n",
    "    # geometric features\n",
    "    kpts_fixed_feat, kpts_moving_feat = net(kpts_fixed, kpts_moving, k)\n",
    "\n",
    "    # inference\n",
    "    dist = pdist2(kpts_fixed, kpts_moving)\n",
    "    ind = (-dist).topk(k1, dim=-1)[1]\n",
    "    candidates = - kpts_fixed.view(1, N_p_fixed, 1, 3) + kpts_moving[:, ind.view(-1), :].view(1, N_p_fixed, k1, 3)\n",
    "    candidates_cost = (kpts_fixed_feat.view(1, N_p_fixed, 1, -1) - kpts_moving_feat[:, ind.view(-1), :].view(1, N_p_fixed, k1, -1)).pow(2).mean(3)\n",
    "    edges, edges_reverse_idx = lbp_graph(kpts_fixed)\n",
    "    messages = torch.zeros((edges.shape[0], k1)).to(device)\n",
    "    candidates_edges0 = candidates[0, edges[:, 0], :, :]\n",
    "    candidates_edges1 = candidates[0, edges[:, 1], :, :]\n",
    "    for _ in range(slbp_iter):\n",
    "        temp_message = torch.zeros((N_p_fixed, k1)).to(device).scatter_add_(0, edges[:, 1].view(-1, 1).expand(-1, k1), messages)\n",
    "        multi_data_cost = torch.gather(temp_message + candidates_cost.squeeze(), 0, edges[:,0].view(-1, 1).expand(-1, k1))\n",
    "        reverse_messages = torch.gather(messages, 0, edges_reverse_idx.view(-1, 1).expand(-1, k1))\n",
    "        multi_data_cost -= reverse_messages\n",
    "        messages = torch.zeros_like(multi_data_cost)\n",
    "        unroll_factor = 32\n",
    "        split = np.array_split(np.arange(multi_data_cost.shape[0]), unroll_factor)\n",
    "        for i in range(unroll_factor):\n",
    "            messages[split[i]] = torch.min(multi_data_cost[split[i]].unsqueeze(1) + slbp_cost_scale*(candidates_edges0[split[i]].unsqueeze(1) - candidates_edges1[split[i]].unsqueeze(2)).pow(2).sum(3), 2)[0]\n",
    "    reg_candidates_cost = (temp_message + candidates_cost.view(-1, k1)).unsqueeze(0)\n",
    "    kpts_fixed_disp_pred = (candidates * F.softmax(slbp_alpha * reg_candidates_cost.view(1, N_p_fixed, -1), 2).unsqueeze(3)).sum(2)\n",
    "    \n",
    "    return kpts_fixed_disp_pred\n",
    "\n",
    "def sLBP_MIND(img_fixed, img_moving, kpts_fixed, kpts_moving):\n",
    "    N_p_fixed = kpts_fixed.shape[1]\n",
    "\n",
    "    # MIND featutes\n",
    "    mind_fixed  = mindssc(img_fixed)\n",
    "    mind_moving = mindssc(img_moving)\n",
    "\n",
    "    # sample patches\n",
    "    kpts_fixed_mind = F.grid_sample(mind_fixed, kpts_fixed.view(1, 1, -1, 1, 3) + patch.view(1, 1, 1, -1, 3), mode='bilinear', padding_mode='border', align_corners=True).permute(0, 2, 3, 1, 4).contiguous().view(1, -1, 12*patch.view(-1,3).shape[0])\n",
    "    kpts_moving_mind = F.grid_sample(mind_moving, kpts_moving.view(1, 1, -1, 1, 3) + patch.view(1, 1, 1, -1, 3), mode='bilinear', padding_mode='border', align_corners=True).permute(0, 2, 3, 1, 4).contiguous().view(1, -1, 12*patch.view(-1,3).shape[0])\n",
    "\n",
    "    # PCA feat embedding\n",
    "    v, mean = pca_train(torch.cat([kpts_fixed_mind, kpts_moving_mind], 1), pca_components)\n",
    "    kpts_fixed_feat = pca_fit(kpts_fixed_mind, v, mean)\n",
    "    kpts_moving_feat = pca_fit(kpts_moving_mind, v, mean)\n",
    "\n",
    "    # inference\n",
    "    dist = pdist2(kpts_fixed, kpts_moving)\n",
    "    ind = (-dist).topk(k1, dim=-1)[1]\n",
    "    candidates = - kpts_fixed.view(1, N_p_fixed, 1, 3) + kpts_moving[:, ind.view(-1), :].view(1, N_p_fixed, k1, 3)\n",
    "    candidates_cost = (kpts_fixed_feat.view(1, N_p_fixed, 1, -1) - kpts_moving_feat[:, ind.view(-1), :].view(1, N_p_fixed, k1, -1)).pow(2).mean(3)\n",
    "    edges, edges_reverse_idx = lbp_graph(kpts_fixed)\n",
    "    messages = torch.zeros((edges.shape[0], k1)).to(device)\n",
    "    candidates_edges0 = candidates[0, edges[:, 0], :, :]\n",
    "    candidates_edges1 = candidates[0, edges[:, 1], :, :]\n",
    "    for _ in range(slbp_iter):\n",
    "        temp_message = torch.zeros((N_p_fixed, k1)).to(device).scatter_add_(0, edges[:, 1].view(-1, 1).expand(-1, k1), messages)\n",
    "        multi_data_cost = torch.gather(temp_message + candidates_cost.squeeze(), 0, edges[:,0].view(-1, 1).expand(-1, k1))\n",
    "        reverse_messages = torch.gather(messages, 0, edges_reverse_idx.view(-1, 1).expand(-1, k1))\n",
    "        multi_data_cost -= reverse_messages\n",
    "        messages = torch.zeros_like(multi_data_cost)\n",
    "        unroll_factor = 32\n",
    "        split = np.array_split(np.arange(multi_data_cost.shape[0]), unroll_factor)\n",
    "        for i in range(unroll_factor):\n",
    "            messages[split[i]] = torch.min(multi_data_cost[split[i]].unsqueeze(1) + slbp_cost_scale*(candidates_edges0[split[i]].unsqueeze(1) - candidates_edges1[split[i]].unsqueeze(2)).pow(2).sum(3), 2)[0]\n",
    "    reg_candidates_cost = (temp_message + candidates_cost.view(-1, k1)).unsqueeze(0)\n",
    "    kpts_fixed_disp_pred = (candidates * F.softmax(slbp_alpha * reg_candidates_cost.view(1, N_p_fixed, -1), 2).unsqueeze(3)).sum(2)\n",
    "\n",
    "    return kpts_fixed_disp_pred\n",
    "\n",
    "def dLBP_GF(kpts_fixed, kpts_moving, net):\n",
    "    N_p_fixed = kpts_fixed.shape[1]\n",
    "\n",
    "    # geometric features\n",
    "    kpts_fixed_feat, kpts_moving_feat = net(kpts_fixed, kpts_moving, k)\n",
    "\n",
    "    # match\n",
    "    cost = discretize(kpts_fixed, kpts_fixed_feat, kpts_moving, kpts_moving_feat)\n",
    "    edges, _ = lbp_graph(kpts_fixed)\n",
    "    messages = torch.zeros_like(cost)\n",
    "    for _ in range(dlbp_iter):\n",
    "        message_data = messages + cost\n",
    "        reg_message_data = minconv(dlbp_cost_scale*message_data, l_width)/dlbp_cost_scale\n",
    "        messages = torch.zeros_like(cost).view(N_p_fixed, -1).scatter_add_(0, edges[:, 0].view(-1, 1).expand(-1, l_width**3), reg_message_data[edges[:, 1]].view(-1, l_width**3)).view_as(cost)\n",
    "        \n",
    "    reg_cost = messages + cost\n",
    "    kpts_fixed_disp_pred = (disp.unsqueeze(1) * F.softmax(dlbp_alpha * reg_cost.view(1, N_p_fixed, -1), 2).unsqueeze(3)).sum(2)\n",
    "    \n",
    "    return kpts_fixed_disp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    methods = ['sLBP', 'sLBP+GF', 'sLBP+MIND', 'dLBP+GF']\n",
    "    tres = torch.zeros(len(methods), len(cases))\n",
    "    times = torch.zeros(len(methods), len(cases))\n",
    "    for i, method in enumerate(methods):\n",
    "        print('Method: {}'.format(method))\n",
    "        print()\n",
    "        for j, case in enumerate(cases):\n",
    "            print('Case {}'.format(case))\n",
    "            print('-------')\n",
    "\n",
    "            # load data and transfer to GPU (asynchronus)\n",
    "            img_fixed   = imgs_fixed[j:j+1].to(device, non_blocking=True)\n",
    "            mask_fixed  = masks_fixed[j:j+1].to(device, non_blocking=True)\n",
    "            img_moving  = imgs_moving[j:j+1].to(device, non_blocking=True)\n",
    "            mask_moving = masks_moving[j:j+1].to(device, non_blocking=True)\n",
    "            \n",
    "            # sample kpts\n",
    "            kpts_fixed = foerstner_kpts(img_fixed, mask_fixed, d=d_fixed)\n",
    "            kpts_moving = foerstner_kpts(F.interpolate(img_moving, scale_factor=scale_moving, mode='trilinear', align_corners=True), (F.interpolate(mask_moving, scale_factor=scale_moving, mode='trilinear') > 0), d=d_moving)\n",
    "            \n",
    "            # preload models\n",
    "            if method in ['sLBP+GF', 'dLBP+GF']:\n",
    "                net = GeometricFeatNet()\n",
    "                net.load_state_dict(torch.load('./models_slbp+gf/case{}_final.pth'.format(case)))\n",
    "                net.to(device)\n",
    "                net.eval()\n",
    "                \n",
    "            # methods\n",
    "            torch.cuda.synchronize()\n",
    "            t0 = time.time()\n",
    "            \n",
    "            if method == 'sLBP':\n",
    "                kpts_fixed_disp_pred = sLBP(kpts_fixed, kpts_moving)\n",
    "            if method == 'sLBP+GF':\n",
    "                kpts_fixed_disp_pred = sLBP_GF(kpts_fixed, kpts_moving, net)\n",
    "            if method == 'sLBP+MIND':\n",
    "                kpts_fixed_disp_pred = sLBP_MIND(img_fixed, img_moving, kpts_fixed, kpts_moving)\n",
    "            if method == 'dLBP+GF':\n",
    "                kpts_fixed_disp_pred = dLBP_GF(kpts_fixed, kpts_moving, net)\n",
    "                 \n",
    "            torch.cuda.synchronize()\n",
    "            t1 = time.time()\n",
    "\n",
    "            # densify\n",
    "            disp_pred = densify(kpts_fixed, kpts_fixed_disp_pred, (D//3, H//3, W//3))\n",
    "            disp_pred = F.interpolate(disp_pred, mode='trilinear', size=(D, H, W))\n",
    "\n",
    "            # eval\n",
    "            tres[i, j] = tre(case, disp_pred).mean()\n",
    "            print('tre: {} (initial: {})'.format(tres[i, j].item(), tre(case, 0*disp_pred).mean().item()))\n",
    "            \n",
    "            # time\n",
    "            times[i, j] = t1-t0\n",
    "            print('time(s): {}'.format(t1-t0))\n",
    "            print()\n",
    "\n",
    "        print('--------------')\n",
    "        print('mean tre: {}'.format(tres[i, :].mean().item()))\n",
    "        print('mean time: {}'.format(times[i, :].mean().item()))\n",
    "        print()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
